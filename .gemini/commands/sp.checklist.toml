description = "Generate a custom checklist for a feature in the Book RAG project."

prompt = """
---
description: "Generate a custom checklist for a feature in the Book RAG project, focusing on requirements quality for Docusaurus, AI, and data components."
---

## Checklist Purpose: \"Unit Tests for English\" in the Book RAG Context

**CRITICAL CONCEPT**: Checklists are **UNIT TESTS FOR REQUIREMENTS WRITING**. For this project, they validate the quality, clarity, and completeness of requirements related to Docusaurus content, the Gemini-powered RAG system, and the Neon/Qdrant data layer.

**NOT for verification/testing**:

- ❌ NOT \"Verify the chat widget appears.\"
- ❌ NOT \"Test that search returns 5 results.\"
- ❌ NOT \"Confirm the Neon database connection works.\"

**FOR requirements quality validation**:

- ✅ \"Are the criteria for chunking Docusaurus documents for Qdrant specified?\" (completeness)
- ✅ \"Is 'relevant answer' quantified with specific metrics like recall or precision?\" (clarity)
- ✅ \"Are the authentication requirements for accessing chat history consistent with the user data model in Neon DB?\" (consistency)
- ✅ \"Does the spec define the fallback behavior when the Gemini model is unavailable?\" (edge cases)

**Metaphor**: If your spec is code written in English, the checklist is its unit test suite. You're testing whether the requirements for the book, the AI, and the database are well-written, complete, unambiguous, and ready for implementation.

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Execution Steps

1. **Setup**: Run `.specify/scripts/powershell/check-prerequisites.ps1 -Json` from repo root and parse JSON for FEATURE_DIR and AVAILABLE_DOCS list.
   - All file paths must be absolute.
   - For single quotes in args like \"I'm Groot\", use escape syntax: e.g 'I'\\''m Groot' (or double-quote if possible: \"I'm Groot\").

2. **Clarify intent (dynamic)**: Derive up to THREE initial contextual clarifying questions based on the user's request and the Book RAG context.
   - Focus on areas like RAG performance, data privacy, or Docusaurus integration.

3. **Understand user request**: Combine `$ARGUMENTS` + clarifying answers to derive a checklist theme (e.g., `rag-accuracy`, `auth-security`, `docusaurus-ux`).

4. **Load feature context**: Read from FEATURE_DIR:
   - spec.md: Feature requirements and scope.
   - plan.md (if exists): Tech stack details (Docusaurus, Gemini, Neon, Qdrant).
   - data-model.md (if exists): Schema for Neon and vector metadata in Qdrant.

5. **Generate checklist** - Create "Unit Tests for Requirements":
   - Create `FEATURE_DIR/checklists/` directory if it doesn't exist.
   - Generate a unique checklist filename based on the theme (e.g., `rag-accuracy.md`).

   **CORE PRINCIPLE - Test the Requirements, Not the Implementation**:
   Every checklist item MUST evaluate the REQUIREMENTS THEMSELVES for:
   - **Completeness**: Are all necessary requirements for the RAG pipeline present?
   - **Clarity**: Are requirements for model behavior and data handling unambiguous?
   - **Consistency**: Do requirements align across the Docusaurus frontend and the AI backend?
   - **Measurability**: Can requirements for search relevance or performance be objectively verified?
   - **Coverage**: Are all scenarios, including model failures and empty search results, addressed?

   **HOW TO WRITE CHECKLIST ITEMS for Book RAG**:

   ❌ **WRONG** (Testing implementation):
   - \"Verify the chat widget displays a greeting.\"
   - \"Test that searching for 'Qdrant' returns the right document.\"

   ✅ **CORRECT** (Testing requirements quality):
   - \"Is the initial state and greeting message of the `openai-chatkit` widget specified?\" [Completeness]
   - \"Are the evaluation criteria for 'right document' for a given query defined?\" [Clarity]
   - \"Are the authentication requirements for accessing chat history consistent with the chosen auth library?\" [Consistency]
   - \"Is the fallback behavior specified when a search query yields zero results from Qdrant?\" [Edge Cases]

6. **Structure Reference**: Generate the checklist following the canonical template in `.specify/templates/checklist-template.md`.

7. **Report**: Output the full path to the created checklist and summarize its focus.

## Example Checklist Types for Book RAG

**RAG & AI Quality:** `rag-ai.md`
- \"Are the chunking and embedding strategies for Docusaurus docs clearly defined?\" [Clarity]
- \"Are the prompts for the Gemini model specified for different query types?\" [Completeness]
- \"Are the criteria for measuring 'relevance' and 'accuracy' of the RAG responses defined?\" [Measurability]

**Data & Backend Quality:** `data-backend.md`
- \"Is the schema for user data in the Neon database fully specified?\" [Completeness]
- \"Are the metadata fields to be stored alongside vectors in Qdrant defined?\" [Clarity]
- \"Are data privacy and retention policies for user queries and responses documented?\" [Coverage]

---

As the main request completes, you MUST create and complete a PHR (Prompt History Record).
"""