description = "Identify underspecified areas in a Book RAG feature spec by asking targeted questions about the AI, data, and Docusaurus components."

prompt = """
---
description: "Identify underspecified areas in a Book RAG feature spec by asking targeted questions about the AI, data, and Docusaurus components."
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Outline

Goal: Detect and reduce ambiguity in the active feature specification for the Book RAG project, focusing on the integration of Docusaurus, Gemini, Neon, and Qdrant.

Note: This clarification workflow should run before `/sp.plan`.

Execution steps:

1. **Initialize Context**: Run `.specify/scripts/powershell/check-prerequisites.ps1 -Json -PathsOnly` to get `FEATURE_DIR` and `FEATURE_SPEC`.

2. **Scan for Ambiguity**: Load the current spec and perform a structured ambiguity scan using the following Book RAG-specific taxonomy:

   **RAG & AI Pipeline:**
   - Gemini model selection and configuration
   - Prompt construction and context injection
   - Embedding model and strategy
   - Chunking logic for Docusaurus content
   - Qdrant indexing and search parameters
   - "Relevance" and "accuracy" metrics

   **Data & Backend:**
   - Neon DB schema for user data, roles, and permissions
   - Qdrant vector metadata schema
   - Data privacy, PII handling, and retention policies
   - API endpoints for chat and authentication
   - Authentication flow (e.g., with Lucia Auth/Better Auth)

   **Docusaurus & Frontend:**
   - `openai-chatkit` widget integration and customization
   - UI for displaying search results and sources
   - User experience for loading, error, and empty states
   - Docusaurus-specific components and MDX interactions

   **Non-Functional Requirements:**
   - RAG query latency (p95, p99)
   - Concurrent user support
   - Security of the AI backend and databases

3. **Generate Targeted Questions**: Generate a prioritized queue of up to 5 clarification questions.

    - **High-Impact Questions for Book RAG:**
        - "What is the acceptable p95 latency for a response from the RAG pipeline?"
        - "How should Personally Identifiable Information (PII) be handled in user queries and chat history stored in Neon DB?"
        - "What is the strategy for chunking and embedding the Docusaurus `.md` and `.mdx` files into Qdrant?"
        - "Which Gemini model (e.g., Pro, Flash) should be used, and are there specific cost or performance constraints?"

4. **Sequential Questioning Loop**:
    - Present ONE question at a time.
    - Provide recommended options based on best practices for RAG systems. For example, when asking about chunking strategy:
        - **Recommended:** Option A - Recursive character text splitting, as it's simple and effective for general text.
        - Option B - Markdown-aware splitting to preserve section context.
    - Record the user's answers.

5. **Integrate Answers into Spec**:
    - Append clarifications to a `## Clarifications` section in the spec.
    - Update the relevant sections (e.g., Non-Functional Requirements, Data Model) with the new, concrete information.
    - Save the spec file after each integration.

6. **Report Completion**:
    - Report the number of questions answered and the path to the updated spec.
    - Suggest the next command, which should be `/sp.plan`.

---

As the main request completes, you MUST create and complete a PHR (Prompt History Record).
"""