"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[4586],{4843:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"physical-ai-book/chapter6/deployment-strategies","title":"6.3 Deployment Strategies","description":"Learning Objectives","source":"@site/docs/physical-ai-book/chapter6/deployment-strategies.md","sourceDirName":"physical-ai-book/chapter6","slug":"/physical-ai-book/chapter6/deployment-strategies","permalink":"/docs/physical-ai-book/chapter6/deployment-strategies","draft":false,"unlisted":false,"editUrl":"https://github.com/muhammad-anas35/RAGai/tree/main/docs/physical-ai-book/chapter6/deployment-strategies.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"5.3 Whole-Body Control","permalink":"/docs/physical-ai-book/chapter5/whole-body-control"},"next":{"title":"Chapter 6: Conversational Robotics","permalink":"/docs/physical-ai-book/chapter6/"}}');var i=r(4848),o=r(8453);const s={},l="6.3 Deployment Strategies",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Model Optimization",id:"model-optimization",level:2},{value:"Quantization",id:"quantization",level:3},{value:"Pruning",id:"pruning",level:3},{value:"Edge Deployment",id:"edge-deployment",level:2},{value:"NVIDIA Jetson",id:"nvidia-jetson",level:3},{value:"Google Coral TPU",id:"google-coral-tpu",level:3},{value:"Real-Time Control Loop",id:"real-time-control-loop",level:2},{value:"Monitoring and Logging",id:"monitoring-and-logging",level:2},{value:"Fallback Strategies",id:"fallback-strategies",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Course Summary",id:"course-summary",level:2}];function d(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"63-deployment-strategies",children:"6.3 Deployment Strategies"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Deploy VLA models on edge devices"}),"\n",(0,i.jsx)(n.li,{children:"Optimize inference for real-time control"}),"\n",(0,i.jsx)(n.li,{children:"Implement model quantization and pruning"}),"\n",(0,i.jsx)(n.li,{children:"Monitor deployed models in production"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"Deploying VLAs on robots requires:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Low latency"}),": <100ms for reactive control"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Efficiency"}),": Run on limited compute (Jetson, edge TPU)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reliability"}),": Handle failures gracefully"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"model-optimization",children:"Model Optimization"}),"\n",(0,i.jsx)(n.h3,{id:"quantization",children:"Quantization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import torch\r\n\r\n# Load full-precision model\r\nmodel = RT2ForConditionalGeneration.from_pretrained("google/rt-2-base")\r\n\r\n# Quantize to INT8\r\nquantized_model = torch.quantization.quantize_dynamic(\r\n    model,\r\n    {torch.nn.Linear},\r\n    dtype=torch.qint8\r\n)\r\n\r\n# Save quantized model\r\ntorch.save(quantized_model.state_dict(), "rt2_int8.pth")\r\n\r\n# Inference speedup: 2-4x, model size: 4x smaller\n'})}),"\n",(0,i.jsx)(n.h3,{id:"pruning",children:"Pruning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import torch.nn.utils.prune as prune\r\n\r\n# Prune 30% of weights\r\nfor module in model.modules():\r\n    if isinstance(module, torch.nn.Linear):\r\n        prune.l1_unstructured(module, name='weight', amount=0.3)\r\n\r\n# Make pruning permanent\r\nfor module in model.modules():\r\n    if isinstance(module, torch.nn.Linear):\r\n        prune.remove(module, 'weight')\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"edge-deployment",children:"Edge Deployment"}),"\n",(0,i.jsx)(n.h3,{id:"nvidia-jetson",children:"NVIDIA Jetson"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Convert to TensorRT\r\nimport tensorrt as trt\r\n\r\n# Build TensorRT engine\r\nwith trt.Builder(TRT_LOGGER) as builder:\r\n    network = builder.create_network()\r\n    # ... build network from ONNX ...\r\n    engine = builder.build_cuda_engine(network)\r\n\r\n# Inference\r\nwith engine.create_execution_context() as context:\r\n    # Allocate buffers\r\n    inputs, outputs, bindings = allocate_buffers(engine)\r\n    \r\n    # Run inference\r\n    context.execute_v2(bindings=bindings)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"google-coral-tpu",children:"Google Coral TPU"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from pycoral.utils import edgetpu\r\nfrom pycoral.adapters import common\r\n\r\n# Load TPU model\r\ninterpreter = edgetpu.make_interpreter("model_edgetpu.tflite")\r\ninterpreter.allocate_tensors()\r\n\r\n# Inference\r\ncommon.set_input(interpreter, input_data)\r\ninterpreter.invoke()\r\noutput = common.output_tensor(interpreter, 0)\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"real-time-control-loop",children:"Real-Time Control Loop"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class RealtimeVLAController(Node):\r\n    def __init__(self):\r\n        super().__init__('vla_controller')\r\n        self.model = load_optimized_model()\r\n        self.control_rate = 10  # Hz\r\n        \r\n    def control_loop(self):\r\n        rate = self.create_rate(self.control_rate)\r\n        \r\n        while rclpy.ok():\r\n            start_time = time.time()\r\n            \r\n            # Get observation\r\n            obs = self.get_observation()\r\n            \r\n            # Inference\r\n            with torch.no_grad():\r\n                action = self.model(obs)\r\n            \r\n            # Send command\r\n            self.robot.execute(action)\r\n            \r\n            # Check latency\r\n            latency = time.time() - start_time\r\n            if latency > 0.1:  # 100ms\r\n                self.get_logger().warn(f\"High latency: {latency*1000:.1f}ms\")\r\n            \r\n            rate.sleep()\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"monitoring-and-logging",children:"Monitoring and Logging"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class ModelMonitor:\r\n    def __init__(self):\r\n        self.metrics = {\r\n            'inference_time': [],\r\n            'success_rate': [],\r\n            'failure_modes': {},\r\n        }\r\n    \r\n    def log_inference(self, obs, action, result):\r\n        # Log inference time\r\n        self.metrics['inference_time'].append(result.latency)\r\n        \r\n        # Log success/failure\r\n        if result.success:\r\n            self.metrics['success_rate'].append(1.0)\r\n        else:\r\n            self.metrics['success_rate'].append(0.0)\r\n            \r\n            # Track failure mode\r\n            mode = result.failure_mode\r\n            self.metrics['failure_modes'][mode] = \\\r\n                self.metrics['failure_modes'].get(mode, 0) + 1\r\n    \r\n    def publish_diagnostics(self):\r\n        avg_latency = np.mean(self.metrics['inference_time'])\r\n        success_rate = np.mean(self.metrics['success_rate'])\r\n        \r\n        self.get_logger().info(\r\n            f\"Latency: {avg_latency*1000:.1f}ms, \"\r\n            f\"Success: {success_rate*100:.1f}%\"\r\n        )\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"fallback-strategies",children:"Fallback Strategies"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class RobustVLAController:\r\n    def predict_with_fallback(self, obs):\r\n        try:\r\n            # Try VLA model\r\n            action = self.vla_model(obs)\r\n            \r\n            # Validate action\r\n            if self.is_valid_action(action):\r\n                return action\r\n            else:\r\n                raise ValueError("Invalid action")\r\n                \r\n        except Exception as e:\r\n            self.get_logger().warn(f"VLA failed: {e}, using fallback")\r\n            \r\n            # Fallback to scripted policy\r\n            return self.scripted_policy(obs)\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.p,{children:["\u2705 ",(0,i.jsx)(n.strong,{children:"Quantization"})," reduces model size and speeds up inference",(0,i.jsx)(n.br,{}),"\n","\u2705 ",(0,i.jsx)(n.strong,{children:"Edge deployment"})," enables on-robot inference",(0,i.jsx)(n.br,{}),"\n","\u2705 ",(0,i.jsx)(n.strong,{children:"Real-time control"})," requires <100ms latency",(0,i.jsx)(n.br,{}),"\n","\u2705 ",(0,i.jsx)(n.strong,{children:"Monitoring"})," tracks performance in production",(0,i.jsx)(n.br,{}),"\n","\u2705 ",(0,i.jsx)(n.strong,{children:"Fallbacks"})," ensure safety when models fail"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"course-summary",children:"Course Summary"}),"\n",(0,i.jsxs)(n.p,{children:["Congratulations! You've completed ",(0,i.jsx)(n.strong,{children:"Physical AI & Humanoid Robotics"}),". You now understand:"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Chapter 1"}),": Physical AI foundations, sensors, humanoid landscape",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Chapter 2"}),": ROS 2 architecture, nodes, packages, launch files",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Chapter 3"}),": Gazebo simulation, URDF, ROS 2 integration",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Chapter 4"}),": NVIDIA Isaac Sim, Isaac Gym, synthetic data",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Chapter 5"}),": Locomotion, manipulation, whole-body control, deployment",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Chapter 6"}),": VLAs, multimodal integration, deployment strategies"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Next Steps"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Build your own humanoid robot project"}),"\n",(0,i.jsx)(n.li,{children:"Contribute to open-source robotics"}),"\n",(0,i.jsx)(n.li,{children:"Join the Physical AI community"}),"\n",(0,i.jsx)(n.li,{children:"Continue learning with advanced courses"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Thank you for learning with us!"})," \ud83e\udd16"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Previous Section"}),": ",(0,i.jsx)(n.a,{href:"/docs/physical-ai-book/chapter6/multimodal-integration",children:"\u2190 6.2 Multimodal Integration"}),(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"End of Textbook"})," \ud83c\udf93"]})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>l});var t=r(6540);const i={},o=t.createContext(i);function s(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);